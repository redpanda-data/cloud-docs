= Pipeline Patterns for Remote MCP Servers
:description: Catalog of pipeline patterns for remote MCP server tools in Redpanda Cloud.
:page-beta: true

This page provides a reference catalog of pipeline patterns designed for use with remote MCP servers in Redpanda Cloud. Use these patterns as building blocks for your own MCP tools. For step-by-step instructions on building, deploying, and testing MCP servers, see xref:ai-agents:mcp/remote/developer-guide.adoc[].

Each pattern is a reusable example for a common MCP tool scenario. Patterns are grouped by use case. All YAML is ready to use in your MCP server project.

For a high-level overview of MCP servers, see xref:ai-agents:mcp/overview.adoc[].

== Data generators

Use xref:develop:connect/components/inputs/about.adoc[`inputs`] to create tools that read data from internal or external systems or generate sample data for testing and development.

This example generates a realistic user event message:

[source,yaml]
----
include::ai-agents:example$generate_input.yaml[]
----

See also: xref:develop:connect/components/inputs/generate.adoc[`generate` input component]

== External API calls

Use xref:develop:connect/components/processors/about.adoc[`processors`] to fetch data from external APIs, databases, or services and return formatted results. This is one of the most common patterns for MCP tools.

[source,yaml]
----
include::ai-agents:example$http_processor.yaml[]
----

See also: xref:develop:connect/components/processors/http.adoc[`http` processor], xref:develop:connect/components/processors/mutation.adoc[`mutation` processor]

== Database queries

Query external databases and return structured results. This pattern is essential for tools that need to access business data.

[source,yaml]
----
include::ai-agents:example$gcp_bigquery_select_processor.yaml[]
----

See also: xref:develop:connect/components/processors/gcp_bigquery_select.adoc[`gcp_bigquery_select` processor], xref:develop:connect/components/processors/sql_select.adoc[`sql_select` processor] (for other databases)

=== Redpanda integration and data publishing

Use these patterns when you need to integrate with Redpanda infrastructure, publish data to topics, or implement caching systems.

=== Data publishers (output patterns)

Use xref:develop:connect/components/outputs/about.adoc[`outputs`] to send data to external systems or build caching systems.

This example publishes a message to a Redpanda topic:

[source,yaml]
----
include::ai-agents:example$redpanda_output.yaml[]
----

See also: xref:develop:connect/components/outputs/redpanda.adoc[`redpanda` output]

=== Caching systems

Use caching to store frequently accessed data, reduce latency, and minimize external API calls. You can implement caching using either Redpanda topics or in-memory stores.

[source,yaml]
----
include::ai-agents:example$redpanda_cache.yaml[]
----

This example implements an in-memory cache for low-latency access to small datasets:

[source,yaml]
----
include::ai-agents:example$memory_cache.yaml[]
----

See also: xref:develop:connect/components/caches/memory.adoc[`memory` cache], Redpanda-backed cache using xref:develop:connect/components/outputs/redpanda.adoc[`redpanda` output]

== Production workflows and observability

Build enterprise-grade tools with error handling, validation, multi-step workflows, and monitoring.

=== Parameter validation and type coercion

Always validate and coerce input parameters to ensure your tools are robust:

[source,yaml]
----
processors:
  - label: validate_params
    mutation: |
      # Validate required parameters
      root = if !this.exists("user_id") {
        throw("user_id parameter is required")
      } else { this }

      # Type coercion with validation
      meta user_id = this.user_id.string()
      meta limit = this.limit.number().catch(10)
      meta start_date = this.start_date.parse_timestamp("2006-01-02").catch(now() - duration("24h"))
----

=== Dynamic configuration

Build tools that adapt their behavior based on input parameters:

[source,yaml]
----
processors:
  - label: dynamic_config
    mutation: |
      # Choose data source based on environment
      meta env = this.environment | "production"
      meta table_name = match @env {
        "dev" => "dev_orders",
        "staging" => "staging_orders",
        "production" => "prod_orders",
        _ => "dev_orders"
      }

      # Adjust query complexity based on urgency
      meta columns = if this.detailed.bool().catch(false) {
        ["order_id", "customer_id", "total", "items", "shipping_address"]
      } else {
        ["order_id", "customer_id", "total"]
      }
----

=== Error handling and fallbacks

Implement error handling to make your tools reliable:

[source,yaml]
----
processors:
  - label: primary_fetch
    try:
      - http:
          url: "https://api.primary.com/data"
          timeout: "10s"
    catch:
      - log:
          message: "Primary API failed, trying fallback"
      - label: fallback_fetch
        http:
          url: "https://api.fallback.com/data"
          timeout: "15s"
      - mutation: |
          root.metadata.source = "fallback"
          root.metadata.warning = "Primary source unavailable"
----

=== Conditional processing

Build tools that branch based on input or data characteristics:

[source,yaml]
----
processors:
  - label: conditional_processing
    switch:
      - check: this.data_type == "json"
        processors:
          - json:
              operator: "parse"
          - mutation: 'root.parsed_data = this'
      - check: this.data_type == "csv"
        processors:
          - csv:
              parse: true
          - mutation: 'root.parsed_data = this'
      - processors:
          - mutation: 'root.error = "Unsupported data type"'
----

[[secrets]]
=== Secrets and credentials

Securely handle multiple credentials and API keys.

Here is an example of using an API key secret.

. Create a secret in the xref:develop:connect/configuration/secret-management.adoc[Secrets Store] with name `EXTERNAL_API_KEY` and your API key as the value.

. Reference the secret in your pipeline configuration:
+
[source,yaml]
----
processors:
  - label: call_external_api
    http:
      url: "https://api.example.com/data"
      verb: GET
      headers:
        Authorization: "Bearer ${secrets.EXTERNAL_API_KEY}"  # <1>
        Accept: "application/json"
----
+
<1> The secret is injected at runtime. Never store the actual API key in your YAML. The actual secret value never appears in your configuration files or logs.

=== Monitoring, debugging, and observability

Use structured logging, request tracing, and performance metrics to gain insights into tool execution.

[source,yaml]
----
include::ai-agents:example$observable_tool.yaml[]
----

Observability features:

* *Correlation IDs*: Use `uuid_v7()` to generate unique request identifiers for tracing
* *Execution timing*: Track how long your tools take to execute using nanosecond precision
* *Structured logging*: Include consistent fields like `request_id`, `duration_ms`, `tool_name`
* *Request/response metadata*: Log input parameters and response characteristics
* *Success tracking*: Monitor whether operations complete successfully

You can test this pattern by invoking the tool with valid and invalid parameters, and observe the structured logs for tracing execution flow. For example, with a user ID of 1, you might see logs like:

[source,json]
----
{
  "metadata": {
    "execution_time_ms": 0.158977,
    "request_id": "019951ab-d07d-703f-aaae-7e1c9a5afa95",
    "success": true,
    "timestamp": "2025-09-16T08:37:18.589Z",
    "tool": "observable_tool"
  },
  "trace": {
    "request_id": "019951ab-d07d-703f-aaae-7e1c9a5afa95",
    "timestamp": "2025-09-16T08:37:18.589Z",
    "tool": "observable_tool",
    "version": "1.0.0"
  },
  "user_id": "1"
}
----

=== Multi-step data enrichment

Build tools that combine data from multiple sources.

This workflow fetches customer data from a SQL database, enriches it with recent order history, and computes summary metrics.

[source,yaml]
----
include::ai-agents:example$customer_enrichment.yaml[]
----

See also: xref:develop:connect/components/processors/sql_select.adoc[`sql_select` processor], xref:develop:connect/guides/bloblang/about.adoc[Bloblang functions] (for data manipulation and aggregations)

=== Workflow orchestration

Coordinate complex workflows with multiple steps and conditional logic.

This workflow simulates a complete order processing pipeline with mock data for inventory and processing tiers. This allows you to test the full logic without needing real external systems.

[source,yaml]
----
include::ai-agents:example$order_workflow.yaml[]
----

For the input `{"order_id": "ORD001", "product_id": "widget-001", "quantity": 5, "total": 250, "customer_tier": "vip"}`, the workflow produces:

[source,json]
----
{
  "assigned_rep": "vip-team@company.com",
  "available_quantity": 100,
  "customer_tier": "vip",
  "estimated_fulfillment": "TBD - calculated based on processing tier",
  "inventory_check": "passed",
  "order_id": "ORD001",
  "order_status": "processed",
  "perks": [
    "expedited_shipping",
    "white_glove_service"
  ],
  "priority_score": 90,
  "processed_at": "2025-09-16T09:05:29.138Z",
  "processing_tier": "vip",
  "processing_time_estimate": "1-2 hours",
  "processing_time_hours": 2,
  "product_id": "widget-001",
  "product_name": "Standard Widget",
  "quantity": 5,
  "total": 250
}
----

Notice how the workflow:

. Preserves original input: `order_id`, `product_id`, `quantity`, `total`, and `customer_tier` pass through unchanged.
. Adds inventory data: `available_quantity`, `product_name`, and `inventory_check` status from the mock lookup.
. Routes by customer tier: Since `customer_tier` is "vip", it gets VIP processing with special `perks` and priority.
. Enriches with processing metadata: `assigned_rep`, `priority_score`, `processing_tier`, and time estimates.
. Finalizes with timestamps: `order_status`, `processed_at`, and calculated `processing_time_hours`.

== Suggested reading

* xref:develop:connect/components/about.adoc[Components overview]
* xref:develop:connect/guides/bloblang/about.adoc[Bloblang guide]
* xref:develop:connect/configuration/secret-management.adoc[Secret management]